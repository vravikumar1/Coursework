{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"},{"sourceId":8298450,"sourceType":"datasetVersion","datasetId":4929734},{"sourceId":8298516,"sourceType":"datasetVersion","datasetId":4929786}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction and Problem Statement\nIn this challenge, we use Generative adversarial networks or GANS. While GANs have broad generative applications, our GAN learns to mimic complex artistic styles, to produce images in the style of Monet. The GAN includes two parts: a generator that creates the images and a discriminator that judges them, and the goal of the generator is to fool the discriminator into accepting its images as real artworks. The generator will be trained to create 7,000 to 10,000 images so convincing that the discriminator thinks they are real Monet paintings.\n\n## About the Data\n\nThe dataset includes 4 files:\n* monet_jpg which includes 300 Monet paintings sized 256x256 in JPEG format\n* monet_tfrec which includes 300 Monet paintings sized 256x256 in TFRecord format\n* photo_jpg which includes 7028 photos sized 256x256 in JPEG format\n* photo_tfrec which includes 7028 photos sized 256x256 in TFRecord format\n\nThe monet directories contain Monet paintings and will be used to train the model.\nThe photo directories contain images that can be stylized by the GAN into the Monet style, and later submitted.\n\nSource of information about the data: https://www.kaggle.com/competitions/gan-getting-started/data","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport math\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom torch.utils.data import Dataset, random_split, DataLoader\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nfrom tqdm.notebook import tqdm\nimport itertools\nimport time\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:15.442247Z","iopub.execute_input":"2024-05-03T18:34:15.442955Z","iopub.status.idle":"2024-05-03T18:34:15.452246Z","shell.execute_reply.started":"2024-05-03T18:34:15.442913Z","shell.execute_reply":"2024-05-03T18:34:15.450831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_monet = \"/kaggle/input/gan-input/monet_jpg/\"\npath_photo = \"/kaggle/input/gan-input/photo_jpg/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:20.479995Z","iopub.execute_input":"2024-05-03T18:34:20.480421Z","iopub.status.idle":"2024-05-03T18:34:20.485644Z","shell.execute_reply.started":"2024-05-03T18:34:20.480388Z","shell.execute_reply":"2024-05-03T18:34:20.484408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)\nThis exploratory data analysis includes:\n1. Displaying a sample of the Monet paintings and images in our directories.\n2. Visualization of histogram distributions of the RGB color channels present in a few Monet paintings vs the photos. This may help identify if there may be any instrinsic differences in the color channel distribution of Monet paintings.\n3. Average RGB color channel values of Monet paintings vs the photographs. This is a more aggregated view and could tell us if there is a significant difference in the color channel distribution of Monet painting wholistically.\n4. Key takeaways from EDA","metadata":{}},{"cell_type":"code","source":"def display_images_in_grid(directory, rows=4, cols=4):\n    num_samples = rows * cols\n    \n    image_files = os.listdir(directory)[:num_samples]\n    \n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n    axes = axes.flatten()\n    \n    for idx, ax in enumerate(axes):\n        if idx < len(image_files):\n            image_path = os.path.join(directory, image_files[idx])\n            image = cv2.imread(image_path)\n            if image is not None:\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                ax.imshow(image)\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:22.979641Z","iopub.execute_input":"2024-05-03T18:34:22.980063Z","iopub.status.idle":"2024-05-03T18:34:22.989731Z","shell.execute_reply.started":"2024-05-03T18:34:22.980031Z","shell.execute_reply":"2024-05-03T18:34:22.988342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_images_in_grid(path_monet)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:24.899616Z","iopub.execute_input":"2024-05-03T18:34:24.900021Z","iopub.status.idle":"2024-05-03T18:34:26.802204Z","shell.execute_reply.started":"2024-05-03T18:34:24.899989Z","shell.execute_reply":"2024-05-03T18:34:26.800783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_images_in_grid(path_photo)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-03T18:34:30.719887Z","iopub.execute_input":"2024-05-03T18:34:30.720315Z","iopub.status.idle":"2024-05-03T18:34:32.577723Z","shell.execute_reply.started":"2024-05-03T18:34:30.720282Z","shell.execute_reply":"2024-05-03T18:34:32.576190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_rgb_histograms(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title('Original Image')\n    \n    plt.subplot(1, 2, 2)\n    colors = ['red', 'green', 'blue']\n    for i, color in enumerate(colors):\n        plt.hist(\n            img[:, :, i].ravel(), \n            bins=256, \n            color=color,\n            alpha=0.5,\n            label=f'{color.capitalize()} Channel'\n        )\n    \n    plt.title('Color Channel Histogram')\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Density')\n    plt.xlim(0, 255)\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:41.185084Z","iopub.execute_input":"2024-05-03T18:34:41.185562Z","iopub.status.idle":"2024-05-03T18:34:41.197741Z","shell.execute_reply.started":"2024-05-03T18:34:41.185525Z","shell.execute_reply":"2024-05-03T18:34:41.196201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#monet pictures\nplot_rgb_histograms(path_monet + os.listdir(path_monet)[0])\nplot_rgb_histograms(path_monet + os.listdir(path_monet)[1])\nplot_rgb_histograms(path_monet + os.listdir(path_monet)[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:45.405492Z","iopub.execute_input":"2024-05-03T18:34:45.405919Z","iopub.status.idle":"2024-05-03T18:34:52.867405Z","shell.execute_reply.started":"2024-05-03T18:34:45.405887Z","shell.execute_reply":"2024-05-03T18:34:52.865957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#photographs\nplot_rgb_histograms(path_photo + os.listdir(path_photo)[0])\nplot_rgb_histograms(path_photo + os.listdir(path_photo)[1])\nplot_rgb_histograms(path_photo + os.listdir(path_photo)[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:34:55.540173Z","iopub.execute_input":"2024-05-03T18:34:55.540600Z","iopub.status.idle":"2024-05-03T18:35:02.543643Z","shell.execute_reply.started":"2024-05-03T18:34:55.540566Z","shell.execute_reply":"2024-05-03T18:35:02.542470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_channel_averages(image_directory):\n    total_sum = np.zeros(3)\n    count = 0\n\n    for filename in os.listdir(image_directory):\n        image_path = os.path.join(image_directory, filename)\n        image = Image.open(image_path)\n        image_array = np.array(image)\n\n        if image_array.shape == (256, 256, 3):\n            total_sum += np.sum(image_array, axis=(0, 1))\n            count += 1\n\n    return total_sum / count if count else np.zeros(3)\n\nmonet_dir = path_monet\nmonet_total = np.zeros(3)\nmonet_count = 0\n\nfor file in os.listdir(monet_dir):\n    img = Image.open(os.path.join(monet_dir, file))\n    img_array = np.array(img)\n    if img_array.shape == (256, 256, 3):\n        monet_total += np.sum(img_array, axis=(0, 1))\n        monet_count += 1\n\naverage_monet_values = monet_total / monet_count if monet_count else np.zeros(3)\n\nphoto_dir = path_photo\nphoto_total = np.zeros(3)\nphoto_count = 0\n\nfor file in os.listdir(photo_dir):\n    img = Image.open(os.path.join(photo_dir, file))\n    img_array = np.array(img)\n    if img_array.shape == (256, 256, 3):\n        photo_total += np.sum(img_array, axis=(0, 1))\n        photo_count += 1\n\naverage_photos_values = photo_total / photo_count if photo_count else np.zeros(3)\n\nchannels = ['Red', 'Green', 'Blue']\nx = np.arange(len(channels))\n\nplt.figure(figsize=(8, 5))\nplt.plot(x, average_monet_values, marker='o', linestyle='-', color='b', label='Monet Paintings', markersize=8)\nplt.plot(x, average_photos_values, marker='s', linestyle='-', color='g', label='Photographs', markersize=8)\n\nplt.xlabel('Color Channel')\nplt.ylabel('Average Value')\nplt.title('Average Channel Values: Monet Paintings vs. Photographs')\nplt.xticks(x, channels)\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:35:05.396743Z","iopub.execute_input":"2024-05-03T18:35:05.397167Z","iopub.status.idle":"2024-05-03T18:36:20.929846Z","shell.execute_reply.started":"2024-05-03T18:35:05.397135Z","shell.execute_reply":"2024-05-03T18:36:20.928623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Key Takeaways from the EDA\nThe density of color pixels seems to be much higher for Monet paintings compared to the photographs. This can be seen in the histogram distributions of the RGB color channels for the subset of Monet paintings compared to the subset of photos. This can also be seen in the visualization of average RGB channel values of Monet paintings vs photographs which seems to suggest there is a significant difference in the color distributions of Monet paintings from photographs.\nMonet's artistic style was known to be vibrant. He used pure, unmixed colors, and his paintings showed intensity of color. This aligns with the color channel distribution we observed in his work.","metadata":{}},{"cell_type":"code","source":"device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:20.932997Z","iopub.execute_input":"2024-05-03T18:36:20.933831Z","iopub.status.idle":"2024-05-03T18:36:20.941716Z","shell.execute_reply.started":"2024-05-03T18:36:20.933782Z","shell.execute_reply":"2024-05-03T18:36:20.939779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\n1. Initialize the training dataset for the model\n2. Load images\n3. **Data preprocessing**, which includes resizing and normalizing the images, and returns them as tensors.","metadata":{}},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, path_monet, path_photo, size=(256, 256), normalize=True):\n        super().__init__()\n        self.monet_files = self._load_files(path_monet)\n        self.photo_files = self._load_files(path_photo)\n        self.transform = self._load_transform(size, normalize)\n\n    def _load_files(self, directory):\n        \"\"\"Load and return a list of file paths from a directory.\"\"\"\n        return [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n\n    def _load_transform(self, size, normalize):\n        \"\"\"Create the transformation pipeline for the images.\"\"\"\n        transformations = [transforms.Resize(size), transforms.ToTensor()]\n        if normalize:\n            transformations.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n        return transforms.Compose(transformations)\n\n    def __getitem__(self, idx):\n        \"\"\"Retrieve a random pair of images, one Monet painting and one photo.\"\"\"\n        monet_path = self.monet_files[idx % len(self.monet_files)]  # Safe index wrapping\n        photo_path = np.random.choice(self.photo_files)\n        \n        monet_img = self.transform(Image.open(monet_path))\n        photo_img = self.transform(Image.open(photo_path))\n        \n        return photo_img, monet_img\n\n    def __len__(self):\n        \"\"\"Return the number of Monet paintings, assuming we always have more photos.\"\"\"\n        return len(self.monet_files)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:33.447902Z","iopub.execute_input":"2024-05-03T18:36:33.448355Z","iopub.status.idle":"2024-05-03T18:36:33.461135Z","shell.execute_reply.started":"2024-05-03T18:36:33.448321Z","shell.execute_reply":"2024-05-03T18:36:33.459649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_ds = ImageDataset(path_monet, path_photo)\nimg_dl = DataLoader(img_ds, batch_size=1, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:35.560346Z","iopub.execute_input":"2024-05-03T18:36:35.560831Z","iopub.status.idle":"2024-05-03T18:36:35.594909Z","shell.execute_reply.started":"2024-05-03T18:36:35.560794Z","shell.execute_reply":"2024-05-03T18:36:35.593367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reverse_normalize(img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n    mean = torch.tensor(mean, dtype=img.dtype, device=img.device)\n    std = torch.tensor(std, dtype=img.dtype, device=img.device)\n    \n    img = img * std[:, None, None] + mean[:, None, None]\n        \n    return img","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:36.901233Z","iopub.execute_input":"2024-05-03T18:36:36.901642Z","iopub.status.idle":"2024-05-03T18:36:36.909274Z","shell.execute_reply.started":"2024-05-03T18:36:36.901612Z","shell.execute_reply":"2024-05-03T18:36:36.907994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the Model\nConstructing the GAN model involves a few steps:\n1. Upsampling functionality\n2. BUild the convolutional layer\n3. Build residual block for the generator\n4. Build the core generator and discriminator functionality\n5. Initialize network weights\n6. Get a sample fake/generated images\n7. Build a Cycle GAN","metadata":{}},{"cell_type":"code","source":"def Upsample(in_channels, out_channels, use_dropout=True, dropout_ratio=0.5):\n    \"\"\"\n    Creates an upsampling block for neural networks.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        use_dropout (bool): Whether to use dropout in the upsampling block.\n        dropout_ratio (float): Dropout ratio if dropout is used.\n\n    Returns:\n        nn.Sequential: The upsampling block.\n    \"\"\"\n    layers = [\n        nn.ConvTranspose2d(in_channels, out_channels, 3, stride=2, padding=1, output_padding=1),\n        nn.InstanceNorm2d(out_channels),\n        nn.GELU()\n    ]\n    \n    if use_dropout:\n        # Insert dropout before the activation function (GELU)\n        layers.insert(2, nn.Dropout(dropout_ratio))\n    \n    return nn.Sequential(*layers)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:39.000150Z","iopub.execute_input":"2024-05-03T18:36:39.000588Z","iopub.status.idle":"2024-05-03T18:36:39.009434Z","shell.execute_reply.started":"2024-05-03T18:36:39.000554Z","shell.execute_reply":"2024-05-03T18:36:39.007922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ConvLayer(in_channels, out_channels, kernel_size=3, stride=2, use_leaky=True, use_inst_norm=True, use_pad=True):\n    \"\"\"\n    Constructs a convolutional layer with configurable options for activation and normalization.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        kernel_size (int): Size of the convolution kernel.\n        stride (int): Stride of the convolution.\n        use_leaky (bool): If True, use LeakyReLU activation, otherwise use GELU.\n        use_inst_norm (bool): If True, use instance normalization, otherwise use batch normalization.\n        use_pad (bool): If True, apply padding to keep dimensions consistent, otherwise no padding.\n\n    Returns:\n        nn.Sequential: The constructed convolutional layer.\n    \"\"\"\n    padding = kernel_size // 2 if use_pad else 0\n\n    conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=True)\n    norm = nn.InstanceNorm2d(out_channels) if use_inst_norm else nn.BatchNorm2d(out_channels)\n\n    activation = nn.LeakyReLU(negative_slope=0.2, inplace=True) if use_leaky else nn.GELU()\n\n    return nn.Sequential(conv, norm, activation)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:43.164831Z","iopub.execute_input":"2024-05-03T18:36:43.165306Z","iopub.status.idle":"2024-05-03T18:36:43.173603Z","shell.execute_reply.started":"2024-05-03T18:36:43.165269Z","shell.execute_reply":"2024-05-03T18:36:43.172531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(self, in_features, use_dropout=True, dropout_ratio=0.5):\n        \"\"\"\n        Initializes the Residual Block used in the generator.\n\n        Args:\n            in_features (int): Number of input and output channels.\n            use_dropout (bool): Whether to include dropout layers.\n            dropout_ratio (float): Dropout ratio if dropout is used.\n        \"\"\"\n        super(ResBlock, self).__init__()\n        \n        layers = [\n            nn.ReflectionPad2d(1),\n            ConvLayer(in_features, in_features, kernel_size=3, stride=1, use_leaky=False, use_pad=False, use_inst_norm=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3, 1, padding=0, bias=True),\n            nn.InstanceNorm2d(in_features)\n        ]\n\n        if use_dropout:\n            layers.insert(2, nn.Dropout(dropout_ratio))\n\n        self.res = nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        Defines the forward pass for the Residual Block.\n\n        Args:\n            x (Tensor): Input tensor to the residual block.\n\n        Returns:\n            Tensor: Output tensor after adding the input to the block's output.\n        \"\"\"\n        return x + self.res(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:45.225145Z","iopub.execute_input":"2024-05-03T18:36:45.225576Z","iopub.status.idle":"2024-05-03T18:36:45.235802Z","shell.execute_reply.started":"2024-05-03T18:36:45.225542Z","shell.execute_reply":"2024-05-03T18:36:45.234544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, in_channels, out_channels, num_res_blocks=6):\n        \"\"\"\n        Initializes the Generator with convolutional and residual blocks.\n\n        Args:\n            in_channels (int): Number of channels in the input image.\n            out_channels (int): Number of channels in the output image.\n            num_res_blocks (int): Number of residual blocks to use.\n        \"\"\"\n        super(Generator, self).__init__()\n\n        initial_layers = [\n            nn.ReflectionPad2d(3),\n            ConvLayer(in_channels, 64, kernel_size=7, stride=1, use_leaky=False, use_pad=False, use_inst_norm=True)\n        ]\n\n        # Downsampling\n        downsampling_layers = [\n            ConvLayer(64, 128, kernel_size=3, stride=2, use_leaky=False),\n            ConvLayer(128, 256, kernel_size=3, stride=2, use_leaky=False)\n        ]\n\n        # Residual blocks\n        res_blocks = [ResBlock(256) for _ in range(num_res_blocks)]\n\n        # Upsampling\n        upsampling_layers = [\n            Upsample(256, 128),\n            Upsample(128, 64)\n        ]\n\n        # Output layer\n        output_layers = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, out_channels, kernel_size=7, padding=0),\n            nn.Tanh()\n        ]\n\n        # Putting it all together\n        self.gen = nn.Sequential(\n            *(initial_layers + downsampling_layers + res_blocks + upsampling_layers + output_layers)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Defines the forward pass of the generator.\n\n        Args:\n            x (Tensor): Input tensor to the generator.\n\n        Returns:\n            Tensor: Output tensor from the generator.\n        \"\"\"\n        return self.gen(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:47.009966Z","iopub.execute_input":"2024-05-03T18:36:47.010401Z","iopub.status.idle":"2024-05-03T18:36:47.023571Z","shell.execute_reply.started":"2024-05-03T18:36:47.010368Z","shell.execute_reply":"2024-05-03T18:36:47.022005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_channels, num_layers=4):\n        \"\"\"\n        Initializes the Discriminator with convolutional layers and LeakyReLU activation.\n\n        Args:\n            in_channels (int): Number of channels in the input image.\n            num_layers (int): Number of convolutional layers in the discriminator.\n        \"\"\"\n        super(Discriminator, self).__init__()\n\n        layers = [\n            # Initial convolution layer\n            nn.Conv2d(in_channels, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        # Buidl convolutional layers based on num_layers\n        for i in range(1, num_layers):\n            in_chs = 64 * (2 ** (i - 1))\n            out_chs = in_chs * 2\n            stride = 1 if i == num_layers - 1 else 2\n            layers.append(ConvLayer(in_chs, out_chs, kernel_size=4, stride=stride, use_leaky=True))\n\n        # Final convolution layer\n        layers.append(nn.Conv2d(out_chs, 1, kernel_size=4, stride=1, padding=1))\n\n        # Sequential model\n        self.disc = nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        Defines the forward pass of the discriminator.\n\n        Args:\n            x (Tensor): Input tensor to the discriminator.\n\n        Returns:\n            Tensor: Output tensor from the discriminator.\n        \"\"\"\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:51.144990Z","iopub.execute_input":"2024-05-03T18:36:51.145993Z","iopub.status.idle":"2024-05-03T18:36:51.156439Z","shell.execute_reply.started":"2024-05-03T18:36:51.145956Z","shell.execute_reply":"2024-05-03T18:36:51.155021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(net, init_type='normal', init_gain=0.02):\n    \"\"\"\n    Initialize network weights.\n    \n    Args:\n        net (nn.Module): Network to initialize.\n        init_type (str): The name of an initialization method: 'normal' or 'xavier'.\n        init_gain (float): Standard deviation of the normal distribution for weight initialization.\n\n    \"\"\"\n    def init_func(m):\n        classname = m.__class__.__name__\n        # Apply initialization to layers\n        if hasattr(m, 'weight') and ('Conv' in classname or 'Linear' in classname):\n            if init_type == 'normal':\n                init.normal_(m.weight.data, 0.0, init_gain)\n            elif init_type == 'xavier':\n                init.xavier_normal_(m.weight.data, gain=init_gain)\n                \n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n\n        elif 'BatchNorm2d' in classname:\n            init.normal_(m.weight.data, 1.0, init_gain)\n            init.constant_(m.bias.data, 0.0)\n\n    net.apply(init_func)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:54.325236Z","iopub.execute_input":"2024-05-03T18:36:54.325654Z","iopub.status.idle":"2024-05-03T18:36:54.337859Z","shell.execute_reply.started":"2024-05-03T18:36:54.325621Z","shell.execute_reply":"2024-05-03T18:36:54.336026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions for the Cycle GAN model","metadata":{}},{"cell_type":"code","source":"def update_req_grad(models, trainable=True):\n    \"\"\"\n    Sets the 'requires_grad' property for all parameters in given models.\n    \n    Args:\n        models (list of nn.Module): A list of PyTorch models whose parameters will be updated.\n        trainable (bool): If True, the model's parameters will require gradients, otherwise they won't.\n    \"\"\"\n    for model in models:\n        for param in model.parameters():\n            param.requires_grad = trainable\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:57.600814Z","iopub.execute_input":"2024-05-03T18:36:57.601252Z","iopub.status.idle":"2024-05-03T18:36:57.607981Z","shell.execute_reply.started":"2024-05-03T18:36:57.601215Z","shell.execute_reply":"2024-05-03T18:36:57.606749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class sample_fake:\n    def __init__(self, max_images=50):\n        \"\"\"\n        Initializes the SampleFake object.\n\n        Args:\n            max_images (int): Maximum number of images to store.\n        \"\"\"\n        self.max_images = max_images\n        self.current_image_index = 0\n        self.images = []\n\n    def __call__(self, images):\n        \"\"\"\n        Samples fake images and updates the stored images.\n\n        Args:\n            images (list of numpy.ndarray): List of generated fake images.\n\n        Returns:\n            list of numpy.ndarray: Sampled fake images.\n        \"\"\"\n        sampled_images = []\n        for image in images:\n            if self.current_image_index < self.max_images:\n                self.images.append(image)\n                sampled_images.append(image)\n                self.current_image_index += 1\n            else:\n                if np.random.rand() > 0.5:\n                    index = np.random.randint(0, self.max_images)\n                    sampled_images.append(self.images[index])\n                    self.images[index] = image\n                else:\n                    sampled_images.append(image)\n        return sampled_images\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:36:59.185032Z","iopub.execute_input":"2024-05-03T18:36:59.185486Z","iopub.status.idle":"2024-05-03T18:36:59.195404Z","shell.execute_reply.started":"2024-05-03T18:36:59.185452Z","shell.execute_reply":"2024-05-03T18:36:59.194228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class lr_sched:\n    def __init__(self, decay_start_epoch=100, total_epochs=200):\n        \"\"\"\n        Initializes a learning rate scheduler with a linear decay after a specified start.\n\n        Args:\n            decay_start_epoch (int): Epoch from which the learning rate starts to decay.\n            total_epochs (int): Total number of epochs after which the learning rate will reach zero.\n        \"\"\"\n        self.decay_start_epoch = decay_start_epoch\n        self.total_epochs = total_epochs\n\n    def step(self, current_epoch):\n        \"\"\"\n        Calculates the learning rate based on the current epoch.\n\n        Args:\n            current_epoch (int): The current epoch number.\n\n        Returns:\n            float: The scaled learning rate.\n        \"\"\"\n        if current_epoch <= self.decay_start_epoch:\n            return 1.0\n        else:\n            decay_progress = (current_epoch - self.decay_start_epoch) / (self.total_epochs - self.decay_start_epoch)\n            return 1.0 - decay_progress\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:01.909710Z","iopub.execute_input":"2024-05-03T18:37:01.910138Z","iopub.status.idle":"2024-05-03T18:37:01.918148Z","shell.execute_reply.started":"2024-05-03T18:37:01.910090Z","shell.execute_reply":"2024-05-03T18:37:01.916787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.losses =[]\n        self.its = []\n        \n    def append(self, loss, it):\n        self.losses.append(loss)\n        self.its.append(it)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:04.240215Z","iopub.execute_input":"2024-05-03T18:37:04.240635Z","iopub.status.idle":"2024-05-03T18:37:04.248626Z","shell.execute_reply.started":"2024-05-03T18:37:04.240604Z","shell.execute_reply":"2024-05-03T18:37:04.247361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cycle GAN Model Build","metadata":{}},{"cell_type":"code","source":"class CycleGAN(object):\n    def __init__(self, in_ch, out_ch, epochs, device, start_lr=2e-4, lmbda=10, idt_coef=0.5, decay_epoch=0):\n        self.epochs = epochs\n        self.decay_epoch = decay_epoch if decay_epoch > 0 else int(self.epochs/2)\n        self.lmbda = lmbda\n        self.idt_coef = idt_coef\n        self.device = device\n        self.gen_mtp = Generator(in_ch, out_ch)\n        self.gen_ptm = Generator(in_ch, out_ch)\n        self.desc_m = Discriminator(in_ch)\n        self.desc_p = Discriminator(in_ch)\n        self.init_models()\n        self.mse_loss = nn.MSELoss()\n        self.l1_loss = nn.L1Loss()\n        self.adam_gen = torch.optim.Adam(itertools.chain(self.gen_mtp.parameters(), self.gen_ptm.parameters()),\n                                         lr = start_lr, betas=(0.5, 0.999))\n        self.adam_desc = torch.optim.Adam(itertools.chain(self.desc_m.parameters(), self.desc_p.parameters()),\n                                          lr=start_lr, betas=(0.5, 0.999))\n        self.sample_monet = sample_fake()\n        self.sample_photo = sample_fake()\n        gen_lr = lr_sched(self.decay_epoch, self.epochs)\n        desc_lr = lr_sched(self.decay_epoch, self.epochs)\n        self.gen_lr_sched = torch.optim.lr_scheduler.LambdaLR(self.adam_gen, gen_lr.step)\n        self.desc_lr_sched = torch.optim.lr_scheduler.LambdaLR(self.adam_desc, desc_lr.step)\n        self.gen_stats = AvgStats()\n        self.desc_stats = AvgStats()\n        \n    def init_models(self):\n        init_weights(self.gen_mtp)\n        init_weights(self.gen_ptm)\n        init_weights(self.desc_m)\n        init_weights(self.desc_p)\n        self.gen_mtp = self.gen_mtp.to(self.device)\n        self.gen_ptm = self.gen_ptm.to(self.device)\n        self.desc_m = self.desc_m.to(self.device)\n        self.desc_p = self.desc_p.to(self.device)\n        \n    def train(self, photo_dl):\n        for epoch in range(self.epochs):\n            start_time = time.time()\n            avg_gen_loss, avg_desc_loss = self.train_one_epoch(photo_dl, epoch)\n            self.log_training(epoch, avg_gen_loss, avg_desc_loss, start_time)\n\n    def train_one_epoch(self, photo_dl, epoch):\n        avg_gen_loss = 0.0\n        avg_desc_loss = 0.0\n        t = tqdm(photo_dl, leave=False, total=len(photo_dl))\n\n        for photo_real, monet_real in t:\n            photo_real, monet_real = photo_real.to(self.device), monet_real.to(self.device)\n            gen_loss, desc_loss = self.process_batch(photo_real, monet_real)\n            avg_gen_loss += gen_loss\n            avg_desc_loss += desc_loss\n            t.set_postfix(gen_loss=gen_loss, desc_loss=desc_loss)\n\n        return avg_gen_loss / len(photo_dl), avg_desc_loss / len(photo_dl)\n\n    def process_batch(self, photo_real, monet_real):\n        gen_loss = self.update_generators(photo_real, monet_real)\n        desc_loss = self.update_discriminators(photo_real, monet_real)\n        return gen_loss.item(), desc_loss.item()\n\n    def update_generators(self, photo_real, monet_real):\n        self.adam_gen.zero_grad()\n    \n        #Generate fakes imgs\n        fake_photo = self.gen_mtp(monet_real)\n        fake_monet = self.gen_ptm(photo_real)\n    \n        cycl_monet = self.gen_ptm(fake_photo)\n        cycl_photo = self.gen_mtp(fake_monet)\n    \n        #identity mapping\n        id_monet = self.gen_ptm(monet_real)\n        id_photo = self.gen_mtp(photo_real)\n    \n        #generator losses\n        idt_loss_monet = self.l1_loss(id_monet, monet_real) * self.lmbda * self.idt_coef\n        idt_loss_photo = self.l1_loss(id_photo, photo_real) * self.lmbda * self.idt_coef\n    \n        cycle_loss_monet = self.l1_loss(cycl_monet, monet_real) * self.lmbda\n        cycle_loss_photo = self.l1_loss(cycl_photo, photo_real) * self.lmbda\n    \n        # Adversarial losses to trick the discrimanots \n        real_label = torch.ones_like(self.desc_m(fake_monet), device=self.device)\n        adv_loss_monet = self.mse_loss(self.desc_m(fake_monet), real_label)\n        adv_loss_photo = self.mse_loss(self.desc_p(fake_photo), real_label)\n    \n        # Total generator loss\n        total_gen_loss = cycle_loss_monet + adv_loss_monet + cycle_loss_photo + adv_loss_photo + idt_loss_monet + idt_loss_photo\n        total_gen_loss.backward()\n        self.adam_gen.step()\n    \n        return total_gen_loss\n\n    def update_discriminators(self, photo_real, monet_real):\n        update_req_grad([self.desc_m, self.desc_p], True)\n        self.adam_desc.zero_grad()\n    \n        #generate fake imgs\n        fake_photo = self.gen_mtp(monet_real).detach()\n        fake_monet = self.gen_ptm(photo_real).detach()\n    \n        real_label = torch.ones_like(self.desc_m(monet_real), device=self.device)\n        fake_label = torch.zeros_like(self.desc_m(fake_monet), device=self.device)\n    \n        #ensure real is classified as real, and fake as fake \n        monet_desc_real_loss = self.mse_loss(self.desc_m(monet_real), real_label)\n        photo_desc_real_loss = self.mse_loss(self.desc_p(photo_real), real_label)\n    \n        monet_desc_fake_loss = self.mse_loss(self.desc_m(fake_monet), fake_label)\n        photo_desc_fake_loss = self.mse_loss(self.desc_p(fake_photo), fake_label)\n    \n        #total loss\n        total_desc_loss = (monet_desc_real_loss + monet_desc_fake_loss + photo_desc_real_loss + photo_desc_fake_loss) / 4\n        total_desc_loss.backward()\n        self.adam_desc.step()\n    \n        return total_desc_loss\n\n    def log_training(self, epoch, avg_gen_loss, avg_desc_loss, start_time):\n        self.gen_lr_sched.step()\n        self.desc_lr_sched.step()\n        time_elapsed = time.time() - start_time\n        self.gen_stats.append(avg_gen_loss, time_elapsed)\n        self.desc_stats.append(avg_desc_loss, time_elapsed)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:07.871353Z","iopub.execute_input":"2024-05-03T18:37:07.871780Z","iopub.status.idle":"2024-05-03T18:37:07.906624Z","shell.execute_reply.started":"2024-05-03T18:37:07.871745Z","shell.execute_reply":"2024-05-03T18:37:07.905308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan = CycleGAN(3, 3, 1, device)\ngan.train(img_dl)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:12.799927Z","iopub.execute_input":"2024-05-03T18:37:12.800382Z","iopub.status.idle":"2024-05-03T18:37:22.273737Z","shell.execute_reply.started":"2024-05-03T18:37:12.800348Z","shell.execute_reply":"2024-05-03T18:37:22.272213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model performance and results","metadata":{}},{"cell_type":"code","source":"def plot_gan_loss():\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Losses\")\n    plt.plot(gan.gen_stats.losses, 'r', label='Generator Loss')\n    plt.plot(gan.desc_stats.losses, 'b', label='Descriminator Loss')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:25.147418Z","iopub.execute_input":"2024-05-03T18:37:25.147828Z","iopub.status.idle":"2024-05-03T18:37:25.154534Z","shell.execute_reply.started":"2024-05-03T18:37:25.147797Z","shell.execute_reply":"2024-05-03T18:37:25.153210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gan_loss()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:28.219785Z","iopub.execute_input":"2024-05-03T18:37:28.220676Z","iopub.status.idle":"2024-05-03T18:37:28.511598Z","shell.execute_reply.started":"2024-05-03T18:37:28.220635Z","shell.execute_reply":"2024-05-03T18:37:28.510232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots(3, 2, figsize=(12, 12))\nfor i in range(3):\n    photo_img, _ = next(iter(img_dl))\n    pred_monet = gan.gen_ptm(photo_img.to(device)).cpu().detach()\n    photo_img = reverse_normalize(photo_img)\n    pred_monet = reverse_normalize(pred_monet)\n    \n    ax[i, 0].imshow(photo_img[0].permute(1, 2, 0))\n    ax[i, 1].imshow(pred_monet[0].permute(1, 2, 0))\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet style Photo\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:31.560207Z","iopub.execute_input":"2024-05-03T18:37:31.560615Z","iopub.status.idle":"2024-05-03T18:37:35.469167Z","shell.execute_reply.started":"2024-05-03T18:37:31.560584Z","shell.execute_reply":"2024-05-03T18:37:35.467239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Key Takeaways:\n* The model is doing well: loss decreases over time/as the number of epochs increases\n* The monet style images are actually quite decent!","metadata":{}},{"cell_type":"markdown","source":"### Image export for submission","metadata":{}},{"cell_type":"code","source":"class PhotoDataset(Dataset):\n    def __init__(self, photo_dir, size=(256, 256), normalize=True):\n        super().__init__()\n        self.photo_dir = photo_dir\n        self.photo_idx = dict()\n        \n        if normalize:\n            self.transform = transforms.Compose([\n                transforms.Resize(size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                \n            ])\n        else:\n            self.transform = transforms.Compose([\n                transforms.Resize(size),\n                transforms.ToTensor()                               \n            ])\n        for i, fl in enumerate(os.listdir(self.photo_dir)):\n            self.photo_idx[i] = fl\n\n    def __getitem__(self, idx):\n        photo_path = os.path.join(self.photo_dir, self.photo_idx[idx])\n        photo_img = Image.open(photo_path)\n        photo_img = self.transform(photo_img)\n        return photo_img\n\n    def __len__(self):\n        return len(self.photo_idx.keys())","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:40.738832Z","iopub.execute_input":"2024-05-03T18:37:40.739319Z","iopub.status.idle":"2024-05-03T18:37:40.751857Z","shell.execute_reply.started":"2024-05-03T18:37:40.739284Z","shell.execute_reply":"2024-05-03T18:37:40.750209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ph_ds = PhotoDataset(path_photo)\nph_dl = DataLoader(ph_ds, batch_size=1, pin_memory=True)\nos.makedirs('/kaggle/working/images')\ntrans = transforms.ToPILImage()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:46.301413Z","iopub.execute_input":"2024-05-03T18:37:46.301834Z","iopub.status.idle":"2024-05-03T18:37:46.316252Z","shell.execute_reply.started":"2024-05-03T18:37:46.301803Z","shell.execute_reply":"2024-05-03T18:37:46.314963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = tqdm(ph_dl, leave=False, total=ph_dl.__len__())\nfor i, photo in enumerate(t):\n    with torch.no_grad():\n        pred_monet = gan.gen_ptm(photo.to(device)).cpu().detach()\n    \n    pred_monet = reverse_normalize(pred_monet)\n    img = trans(pred_monet[0]).convert(\"RGB\")\n    \n    img.save(\"/kaggle/working/images/\" + str(i+1) + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:37:49.460732Z","iopub.execute_input":"2024-05-03T18:37:49.462001Z","iopub.status.idle":"2024-05-03T18:38:00.436921Z","shell.execute_reply.started":"2024-05-03T18:37:49.461962Z","shell.execute_reply":"2024-05-03T18:38:00.435066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/working\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:38:04.900003Z","iopub.execute_input":"2024-05-03T18:38:04.900416Z","iopub.status.idle":"2024-05-03T18:38:04.934108Z","shell.execute_reply.started":"2024-05-03T18:38:04.900386Z","shell.execute_reply":"2024-05-03T18:38:04.932908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = [2e-4]\nbeta_1 = [0.5]\nbeta_2 = [0.999]  \ndf_results = pd.DataFrame({'Learning Rate': learning_rate, 'Beta 1': beta_1, 'Beta 2': beta_2})\nprint(df_results)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T18:38:18.663765Z","iopub.execute_input":"2024-05-03T18:38:18.664243Z","iopub.status.idle":"2024-05-03T18:38:18.687581Z","shell.execute_reply.started":"2024-05-03T18:38:18.664208Z","shell.execute_reply":"2024-05-03T18:38:18.686138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}